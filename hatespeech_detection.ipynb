{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hatespeech_detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxIMYWzxJgTx"
      },
      "source": [
        "!pip install SentencePiece\n",
        "!pip install transformers\n",
        "!pip install git+https://github.com/PytorchLightning/pytorch-lightning.git@master --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzfdf8FNBZve"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "import transformers\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from google.colab import drive\n",
        "from torch.utils.data import random_split, DataLoader, TensorDataset, RandomSampler\n",
        "from transformers import AlbertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx0DU4wXCdkC",
        "outputId": "48c285de-7b0d-4bf9-af84-b292fb159a9a"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KemYP9LoKWBf"
      },
      "source": [
        "trd = pd.read_csv('/content/drive/My Drive/bert-tf/Khilnani_LP_train_data.csv')\n",
        "ted = pd.read_csv('/content/drive/My Drive/bert-tf/Khilnani_LP_test_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGcC3yVqKtxb",
        "outputId": "67127998-2c63-4083-8cfd-edc334d71113"
      },
      "source": [
        "trd.describe(), trd['tweet'][3], len(trd), trd.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                 id         label\n",
              " count  31962.000000  31962.000000\n",
              " mean   15981.500000      0.070146\n",
              " std     9226.778988      0.255397\n",
              " min        1.000000      0.000000\n",
              " 25%     7991.250000      0.000000\n",
              " 50%    15981.500000      0.000000\n",
              " 75%    23971.750000      0.000000\n",
              " max    31962.000000      1.000000,\n",
              " '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
              " 31962,\n",
              " Index(['id', 'label', 'tweet'], dtype='object'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR5VzMrYFwTL",
        "outputId": "a9311b1c-f50a-4d8d-fd63-eec1e777d71b"
      },
      "source": [
        "ted.describe(), len(ted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                 id\n",
              " count  17197.000000\n",
              " mean   40561.000000\n",
              " std     4964.490625\n",
              " min    31963.000000\n",
              " 25%    36262.000000\n",
              " 50%    40561.000000\n",
              " 75%    44860.000000\n",
              " max    49159.000000, 17197)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvRepBSMG2iY",
        "outputId": "781f6d1c-e493-4e2b-a62f-97f0b6cd7da1"
      },
      "source": [
        "trd.head(1), ted.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   id  label                                              tweet\n",
              " 0   1      0   @user when a father is dysfunctional and is s...,\n",
              "       id                                              tweet\n",
              " 0  31963  #studiolife #aislife #requires #passion #dedic...\n",
              " 1  31964   @user #white #supremacists want everyone to s...\n",
              " 2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
              " 3  31966  is the hp and the cursed child book up for res...\n",
              " 4  31967    3rd #bihday to my amazing, hilarious #nephew...)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoJeWgTfUNGX"
      },
      "source": [
        "def remove_mentions(tweets_list):\n",
        "  proc_list = []\n",
        "  for ind, d in enumerate(tweets_list):\n",
        "    l = re.sub(r'(\\s|^)@\\w+', '', d)\n",
        "    proc_list.append(l.strip())\n",
        "  return proc_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m7qcXkObFFB"
      },
      "source": [
        "train_full = remove_mentions(trd['tweet'])\n",
        "trlabels = [int(i) for i in trd['label']]\n",
        "test_data = remove_mentions(ted['tweet'])\n",
        "# test_labels = [int(i) for i in ted['label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbWja0vOyALv"
      },
      "source": [
        "class DataModule(pl.LightningDataModule):\n",
        "  def __init__(self, train_data, train_labels,\n",
        "               test_data, batch_size=32):\n",
        "    super().__init__()\n",
        "    self.train_data = train_data\n",
        "    self.train_labels = train_labels\n",
        "    self.test_data = test_data\n",
        "    self.tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
        "    self.batch_size = batch_size\n",
        "  def setup(self):\n",
        "    trk = self.tokenizer(\n",
        "            self.train_data,  # Sentence to encode.\n",
        "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
        "            max_length=64,  # Pad & truncate all sentences.\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,  # Construct attn. masks.\n",
        "            return_tensors='pt'  # Return pytorch tensors.\n",
        "        )\n",
        " \n",
        "    tek = self.tokenizer(\n",
        "            self.test_data,  # Sentence to encode.\n",
        "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
        "            max_length=64,  # Pad & truncate all sentences.\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,  # Construct attn. masks.\n",
        "            return_tensors='pt'  # Return pytorch tensors.\n",
        "        )\n",
        "    print(trk.keys())\n",
        "    tr_inp_ids = trk['input_ids']\n",
        "    tr_attn_mask = trk['attention_mask']\n",
        "    tr_token_type_ids = trk['token_type_ids']\n",
        "    te_inp_ids = tek['input_ids']\n",
        "    te_attn_mask = tek['attention_mask']\n",
        "    te_token_type_ids = tek['token_type_ids']\n",
        "    tr_labels = torch.tensor(self.train_labels)\n",
        "    # print(list(map(type, [tr_inp_ids, tr_attn_mask, tr_token_type_ids, tr_labels])))\n",
        "    tr_dataset = TensorDataset(tr_inp_ids, tr_attn_mask, tr_token_type_ids, tr_labels)\n",
        "    train_size = int(0.9 * len(tr_dataset))\n",
        "    val_size = len(tr_dataset) - train_size\n",
        "    print('{:>5,} training samples'.format(train_size))\n",
        "    print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "    self.train_dataset, self.val_dataset = random_split(\n",
        "        tr_dataset, [train_size, val_size],\n",
        "        generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    self.test_dataset = TensorDataset(te_inp_ids, te_attn_mask, te_token_type_ids)\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(\n",
        "            self.train_dataset,  # The training samples.\n",
        "            sampler=RandomSampler(\n",
        "                self.train_dataset),  # Select batches randomly\n",
        "            batch_size=self.batch_size  # Trains with this batch size.\n",
        "        )\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(\n",
        "            self.val_dataset,  # The training samples.\n",
        "            sampler=RandomSampler(self.val_dataset),  # Select batches randomly\n",
        "            batch_size=self.batch_size,  # Trains with this batch size.\n",
        "            shuffle=False)\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(\n",
        "            self.test_dataset,  # The training samples.\n",
        "            sampler=RandomSampler(self.test_dataset),  # Select batches randomly\n",
        "            batch_size=self.batch_size,  # Trains with this batch size.\n",
        "            shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLUHc6W4FNAa",
        "outputId": "f8f136d1-da17-4c77-81ba-af821dd1a9a5"
      },
      "source": [
        "dls = DataModule(train_full, trlabels, test_data)\n",
        "dls.setup()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "28,765 training samples\n",
            "3,197 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgDPkBGzFeOG",
        "outputId": "62912a84-d972-40f7-c07e-a1197502c757"
      },
      "source": [
        "a = next(iter(dls.val_dataloader()))\n",
        "a[0].shape, a[1].shape, a[2].shape, a[3].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]),\n",
              " torch.Size([32, 64]),\n",
              " torch.Size([32, 64]),\n",
              " torch.Size([32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}